<!DOCTYPE html>
<html lang="en-US" class="fontawesome-i2svg-active fontawesome-i2svg-complete">
<head>
    <meta charset="UTF-8">
    <meta content="width=device-width, initial-scale=1" name="viewport">
    <title>Jiahao Ma</title>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-MFWSBLRKG0"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-MFWSBLRKG0');
    </script>

    <link href="https://fonts.googleapis.com/css2?family=Google+Sans:wght@400;500;700&family=Roboto:wght@400;500;700&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">
    <link href="https://cdn.jsdelivr.net/npm/bulma@0.9.3/css/bulma.min.css" rel="stylesheet">
    <link href="src\index.css" rel="stylesheet">

    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <script defer src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/js/all.min.js"></script>
    <script src="src\index.js"></script>
</head>

<body>
    <section class="hero">
        <div class="hero-body container is-max-desktop">
            <div class="columns is-vcentered">
                <div class="column is-4">
                    <div class="portrait">
                        <img src="figures/JiahaoMa.jpg" alt="Jiahao Ma">
                    </div>
                </div>
                <div class="column">
                    <h1 class="title">
                        <b>Hello, I'm Jiahao Ma</b>
                    </h1>
                    <div class="content has-text-justified">
                        <p>I am a second-year PhD student in Computer Science at <a href="https://grail.cs.washington.edu/">Australian National University</a> where I am advised by <a href="https://users.cecs.anu.edu.au/~mliu/">Miaomiao Liu</a>,
                        <a href="https://people.csiro.au/a/d/david-ahmedtaristizabal">David Ahmedt Aristizabal</a> and <a href="https://people.csiro.au/N/C/Chuong-Nguyen">Chuong Nguyen</a>. Before that, 
                        I received my Master of Philosophy degree supervised by <a href="https://zheng-lab.cecs.anu.edu.au/">Liang Zheng</a> from Australian National University in 2023. 
                        My current research interest lies in 3D reconstruction and novel view synthesis.</p>

                        <div class="buttons">
                            <a class="external-link button is-light" href="https://scholar.google.com/citations?user=IMr-5akAAAAJ&hl=zh-CN">
                                <span class="icon"><i class="fab fa-google"></i></span>
                                <span>Scholar</span>
                            </a>
                            
                            <a class="external-link button is-light" href="https://github.com/Jiahao-Ma">
                                <span class="icon"><i class="fab fa-github"></i></span>
                                <span>Github</span>
                            </a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <div class="hr">
        <div class="container">
            <hr>
        </div>
    </div>

    <section class="section">
        <div class="container is-max-desktop">
            <h2 class="title is-3">Publications </h2>
            
            <div class="publication-block columns">
                <div class="column is-2">
                    <img alt="SOAF: Scene Occlusion-aware Neural Acoustic Field" src="./figures/DCHM.jpg">
                </div>

                <div class="column">
                    <div class="content">
                        <h3 class="publication-title"><a href="https://huiyu-gao.github.io/SOAF/">DCHM: Depth-Consistent Human Modeling for Multiview Detection</a></h3>
                        <div class="publication-authors">
                            <span class="author-block author-me">
                                <a href="https://jiahao-ma.github.io/">Jiahao Ma</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=OfOGvmUAAAAJ&hl=en">Tianyu Wang</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://users.cecs.anu.edu.au/~mliu/">Miaomiao Liu</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://people.csiro.au/a/d/david-ahmedtaristizabal">David Ahmedt-Aristizabal</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://people.csiro.au/N/C/Chuong-Nguyen">Chuong Nguyen</a>
                            </span>
                        </div>
                        <div class="publication-venue">
                            <span>ICCV, 2025</span>
                            <!-- <span>Arxiv preprint</span> -->
                        </div>
                        <p class="publication-description">DCHM creates consistent point clouds in sparse-view, large-scaled, and crowded scenarios via superpixel Gaussian splatting for label-free multi-view detection.</p>
                        <div class="publication-links buttons field has-addons">
                            <a class="external-link button is-small is-ghost" href="">
                                <span class="icon"><i class="fas fa-globe-asia"></i></span>
                                <span>Project Page</span>
                            </a>
                            <a class="external-link button is-small is-ghost" href="">
                                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                                <span>Paper</span>
                            </a>
                        </div>
                    </div>
                </div>

            </div>

            <div class="publication-block columns">
                <div class="column is-2">
                    <img alt="SOAF: Scene Occlusion-aware Neural Acoustic Field" src="./figures/SOAF.jpg">
                </div>

                <div class="column">
                    <div class="content">
                        <h3 class="publication-title"><a href="https://huiyu-gao.github.io/SOAF/">SOAF: Scene Occlusion-aware Neural Acoustic Field</a></h3>
                        <div class="publication-authors">
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=QofCy6EAAAAJ&hl=en&oi=ao">Huiyu Gao*</a>,
                            </span>
                            <span class="author-block author-me">
                                <a href="https://jiahao-ma.github.io/">Jiahao Ma*</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://people.csiro.au/a/d/david-ahmedtaristizabal">David Ahmedt-Aristizabal</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://people.csiro.au/N/C/Chuong-Nguyen">Chuong Nguyen</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://users.cecs.anu.edu.au/~mliu/">Miaomiao Liu</a>,
                            </span>
                        </div>
                        <div class="publication-venue">
                            <!-- <span>Conference on Computer Vision and Pattern Recognition (CVPR 2024)</span> -->
                            <span>Arxiv preprint</span>
                        </div>
                        <p class="publication-description">SOAF models room geometry and wall occlusions for sound propagation.</p>
                        <div class="publication-links buttons field has-addons">
                            <a class="external-link button is-small is-ghost" href="https://huiyu-gao.github.io/SOAF/">
                                <span class="icon"><i class="fas fa-globe-asia"></i></span>
                                <span>Project Page</span>
                            </a>
                            <a class="external-link button is-small is-ghost" href="https://arxiv.org/pdf/2407.02264v1">
                                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                                <span>Paper</span>
                            </a>
                        </div>
                    </div>
                </div>

            </div>
            
            <div class="publication-block columns">
                <div class="column is-2">
                    <img alt="HashPoint: Accelerated Point Searching and Sampling for Neural Rendering" src="./figures/h3.jpg">
                </div>

                <div class="column">
                    <div class="content">
                        <h3 class="publication-title"><a href="https://jiahao-ma.github.io/hashpoint/">HashPoint: Accelerated Point Searching and Sampling for Neural Rendering</a></h3>
                        <div class="publication-authors">
                            <span class="author-block author-me">
                                <a href="https://jiahao-ma.github.io/">Jiahao Ma</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://users.cecs.anu.edu.au/~mliu/">Miaomiao Liu</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://people.csiro.au/a/d/david-ahmedtaristizabal">David Ahmedt-Aristizabal</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://people.csiro.au/N/C/Chuong-Nguyen">Chuong Nguyen</a>,
                            </span>
                        </div>
                        <div class="publication-venue">
                            <!-- <span>Conference on Computer Vision and Pattern Recognition (CVPR 2024)</span> -->
                            <span>CVPR, 2024</span>
                            <span class="publication-venue-emph">Highlight<span>
                        </div>
                        <p class="publication-description">HashPoint accelerates the volume rendering by combining rasterization with ray tracing.</p>
                        <div class="publication-links buttons field has-addons">
                            <a class="external-link button is-small is-ghost" href="https://jiahao-ma.github.io/hashpoint/">
                                <span class="icon"><i class="fas fa-globe-asia"></i></span>
                                <span>Project Page</span>
                            </a>
                            <a class="external-link button is-small is-ghost" href="https://openaccess.thecvf.com/content/CVPR2024/html/Ma_HashPoint_Accelerated_Point_Searching_and_Sampling_for_Neural_Rendering_CVPR_2024_paper.html">
                                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                                <span>Paper</span>
                            </a>
                        </div>
                    </div>
                </div>

            </div>

            <div class="publication-block columns">
                <div class="column is-2">
                    <img alt="Multiview Detection with Cardboard Human Modeling" src="./figures/MvCHM.png">
                </div>
    
                <div class="column">
                    <div class="content">
                        <h3 class="publication-title"><a href="https://jiahao-ma.github.io/hashpoint/">Multiview Detection with Cardboard Human Modeling</a></h3>
                        <div class="publication-authors">
                            <span class="author-block author-me">
                                <a href="https://jiahao-ma.github.io/">Jiahao Ma*</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=zFKr1YYAAAAJ&hl=en">Zicheng Duan*</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=vNHqr3oAAAAJ&hl=en">Liang Zheng</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://people.csiro.au/N/C/Chuong-Nguyen">Chuong Nguyen</a>,
                            </span>
                        </div>
                        <div class="publication-venue">
                            <!-- <span>Conference on Computer Vision and Pattern Recognition (CVPR 2024)</span> -->
                            <span>ACCV, 2024</span>
                        </div>
                        <p class="publication-description">Cardboard human modeling aggregate multiview pedestrian features.</p>
                        <div class="publication-links buttons field has-addons">
                            <a class="external-link button is-small is-ghost" href="https://github.com/Jiahao-Ma/MvCHM">
                                <span class="icon"><i class="fab fa-github"></i></span>
                                <span>Code</span>
                            </a>
                            <a class="external-link button is-small is-ghost" href="https://arxiv.org/pdf/2207.02013">
                                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                                <span>Paper</span>
                            </a>
                        </div>
                    </div>
                </div>
            </div>

            <div class="publication-block columns">
                <div class="column is-2">
                    <img alt="Voxelized 3D Feature Aggregation for Multiview Detection" src="./figures/vfa1.jpg">
                </div>
    
                <div class="column">
                    <div class="content">
                        <h3 class="publication-title"><a href="https://jiahao-ma.github.io/hashpoint/">Voxelized 3D Feature Aggregation for Multiview Detection</a></h3>
                        <div class="publication-authors">
                            <span class="author-block author-me">
                                <a href="https://jiahao-ma.github.io/">Jiahao Ma</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?hl=zh-CN&user=KyaPzTEAAAAJ">Jinguang Tong</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?hl=zh-CN&user=3xT-7nsAAAAJ">Shan Wang</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=zFKr1YYAAAAJ&hl=en">Zicheng Duan</a>,
                            </span>
                            <span class="author-block">
                                <a href="https://people.csiro.au/N/C/Chuong-Nguyen">Chuong Nguyen</a>,
                            </span>
                        </div>
                        <div class="publication-venue">
                            <!-- <span>Conference on Computer Vision and Pattern Recognition (CVPR 2024)</span> -->
                            <span>DICTA, 2024</span>
                        </div>
                        <p class="publication-description"> VFA, a voxelized 3D feature aggregation method, improves multiview detection accuracy by reducing occlusion and projection errors.</p>
                        <div class="publication-links buttons field has-addons">
                            <a class="external-link button is-small is-ghost" href="https://github.com/Robert-Mar/VFA">
                                <span class="icon"><i class="fab fa-github"></i></span>
                                <span>Code</span>
                            </a>
                            <a class="external-link button is-small is-ghost" href="https://github.com/Robert-Mar/MultiviewC">
                                <span class="icon"><i class="fas fa-database"></i></span>
                                <span>Dataset</span>
                            </a>
                            <a class="external-link button is-small is-ghost" href="https://arxiv.org/abs/2112.03471">
                                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                                <span>Paper</span>
                            </a>
                        </div>
                    </div>
                </div>
            </div>
            <p class="publication-description"> <strong>*</strong> denotes equal contribution.</p>

        </div>
    </section>
    <section class="section">
        <div class="container is-max-desktop">
            <h2 class="title is-3">Projects</h2>

            <div class="publication-block columns">
                <div class="column is-4">  <!-- Adjust this value for larger image column -->
                    <img src="./figures/MultiviewC.gif" alt="MultiviewC GIF" width="100%" height="100%">
                </div>                
            
                <div class="column is-8">
                    <div class="content">
                        <h3 class="publication-title"><a href="https://github.com/Jiahao-Ma/MultiviewC">Multiview animal monitoring</a></h3>
                        <p>Multiview detection algorithm design and synthetic dataset generation.</p>
                        <ul>
                            <li><strong>Publication:</strong> The paper has been accepted by DICTA 2024.</li>
                            <li><strong>MultiviewC dataset:</strong> Proposed the MultiviewC dataset for multiview animal action recognition, 3D detection, and tracking.</li>
                        </ul>
                        <div class="publication-links buttons field has-addons">
                            <a class="external-link button is-small is-ghost" href="https://github.com/Jiahao-Ma/MultiviewC">
                                <span class="icon"><i class="fas fa-database"></i></span>
                                <span>Dataset+Engine</span>
                            </a>
                            <a class="external-link button is-small is-ghost" href="https://arxiv.org/abs/2112.03471">
                                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                                <span>Paper</span>
                            </a>
                        </div>
                    </div>
                </div>
            </div>
            

        </div>
    </section>
</body>
</html>